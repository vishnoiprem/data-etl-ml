# Data ETL and ML Project

This project includes components for Machine Learning (ML), ETL processes, Spark jobs, and general Python scripts.

## Project Structure

- **ML/**: Machine learning related code and models.
- **Spark/**: Spark jobs and related scripts.
- **ETL/**: ETL pipelines and configuration.
- **Python/**: General-purpose Python scripts and modules.
- **tests/**: Unit tests for all components.

## Getting Started

### Prerequisites

- Python 3.x
- Apache Spark
- Jupyter Notebook

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/data-etl-ml.git
   cd data-etl-ml
   ```

2. Install required Python packages:
   ```bash
   pip install -r requirements.txt
   
spark-submit --master "local[*]" /Users/prem/PycharmProjects/data-etl-ml/Spark/scripts/pyspark_resource_management.py
   ```

### Usage

- **ML**: Run the training script using `python ML/src/train.py`.
- **Spark**: Execute Spark jobs using the scripts in `Spark/scripts/`.
- **ETL**: Run ETL pipelines using the scripts in `ETL/scripts/`.


## License

This project is licensed under the MIT License - see the `LICENSE` file for details.
