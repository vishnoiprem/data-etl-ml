# 7 Advanced Prompting Techniques That Will 10x Your AI Results [2025]

*From basic questions to expert-level prompts â€” the complete guide*

---

## The Prompting Gap

Here's a secret most people don't know: **Two people can use the exact same AI and get wildly different results.**

One person asks: "Explain quantum computing."
Another asks: "Explain quantum computing like I'm 10, using an analogy about sorting socks, step by step."

Same AI. Completely different outputs.

The difference? **Prompting technique.**

In this guide, I'll show you 7 advanced prompting techniques that professional AI engineers use daily:

| # | Technique | What It Does |
|---|-----------|-------------|
| 1 | **Chain-of-Thought (CoT)** | Step-by-step reasoning |
| 2 | **ReAct** | Reasoning + real actions |
| 3 | **Skeleton-of-Thought (SoT)** | 2x faster long answers |
| 4 | **Self-Refine** | AI improves its own work |
| 5 | **Rephrase and Respond (RaR)** | Clarifies ambiguous questions |
| 6 | **Chain-of-Verification (CoVe)** | Self-checks for accuracy |
| 7 | **CoNLI** | Eliminates hallucinations |

Let's break each one down.

---

## 1. Chain-of-Thought (CoT): Think Step by Step

### The Problem

AI often jumps to answers without showing its work. This leads to errors, especially in math and logic.

### The Solution

Add the magic words: **"Let's think step by step."**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CoT = Question + "Think step by step"                     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example

**Without CoT:**
```
Q: A bat and ball cost $1.10. The bat costs $1 more than the ball. 
   How much does the ball cost?
A: $0.10   (WRONG!)
```

**With CoT:**
```
Q: [Same question] Let's think step by step.

A: Step 1: Let ball = x
   Step 2: Bat = x + $1
   Step 3: x + (x + $1) = $1.10
   Step 4: 2x = $0.10
   Step 5: x = $0.05
   
   The ball costs $0.05 âœ“
```

### When to Use

| Perfect For          |  Skip For |
|----------------------|-----------|
| Math problems        | Simple facts |
| Logic puzzles        | Yes/no questions |
| Multi-step reasoning | Definitions |
| Debugging code       | Creative writing |

### Copy-Paste Template

```
[YOUR QUESTION]

Think through this step by step:
1. What do we know?
2. What do we need to find?
3. Work through the logic
4. Verify the answer
```

---

## 2. ReAct: Reasoning + Acting

### The Problem

CoT can reason about wrong information. The AI confidently explains... completely made-up facts.

### The Solution

Let AI actually DO things â€” search, calculate, verify.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE ReAct LOOP                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   THINK: "What do I need to find out?"                      â”‚
â”‚      â†“                                                      â”‚
â”‚   ACT: Search["query"] or Calculate["2+2"]                  â”‚
â”‚      â†“                                                      â”‚
â”‚   OBSERVE: "Results say..."                                 â”‚
â”‚      â†“                                                      â”‚
â”‚   Repeat until you have the answer                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example

**Question:** "Who won the 2024 Super Bowl and what's the winner's city population?"

```
THINK: I need: 1) Super Bowl winner, 2) Their city's population

ACT: Search["2024 Super Bowl winner"]
OBSERVE: Kansas City Chiefs won Super Bowl LVIII

THINK: Now I need Kansas City's population

ACT: Search["Kansas City population 2024"]
OBSERVE: Kansas City has ~520,000 people (city proper)

ANSWER: The Kansas City Chiefs won. KC has ~520,000 people.
```

### When to Use

| Perfect For          | Skip For         |
|----------------------|------------------|
| Current events       | Opinions         |
| Fact verification    | Brainstorming    |
| Research tasks       | Creative writing |
| Multi-source queries | Simple lookups   |



---

## 3. Skeleton-of-Thought (SoT): 2x Faster Answers

### The Problem

Long answers take forever. AI generates word by word by word...

### The Solution

**Outline first, then expand ALL points in parallel.**

```
Normal:                     SoT:
                           
Point 1 â†’ wait             Skeleton (5 sec)
Point 2 â†’ wait                  â†“
Point 3 â†’ wait             [Point 1] [Point 2] [Point 3]
                                  â†“ ALL AT ONCE â†“
Total: 30 sec              Total: 15 sec (2x faster!)
```

### The Two Phases

**Phase 1: Generate Skeleton**
```
Create ONLY a skeleton for this question.
- Number points 1., 2., 3.
- Each point: 3-5 words only
- 3-10 points total

Question: Benefits of remote work?
```

Output:
```
1. Flexible schedule
2. No commute time
3. Better work-life balance
4. Cost savings
5. Higher productivity
```

**Phase 2: Expand All Points (Simultaneously)**

Each point gets expanded at the same time = **2x speed boost!**

### When to Use

| Perfect For          | Skip For         |
|----------------------|------------------|
| Multi-point answers  | Simple questions |
| List-based questions | Math problems    |
| Long-form content    | Short answers    |
| Speed-critical apps  | Narratives       |


---

## 4. Self-Refine: Generate â†’ Critique â†’ Improve

### The Problem

First drafts are rarely perfect. But most people accept AI's first answer.

### The Solution

**Make AI its own editor.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SELF-REFINE LOOP                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   1. GENERATE â†’ Initial response                            â”‚
â”‚         â†“                                                   â”‚
â”‚   2. CRITIQUE â†’ "What's wrong with this?"                   â”‚
â”‚         â†“                                                   â”‚
â”‚   3. REFINE â†’ Fix all issues                                â”‚
â”‚         â†“                                                   â”‚
â”‚   4. REPEAT â†’ Until good enough                             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Dialogue Improvement

**User:** "I'm interested in playing table tennis."

**v1 (Initial):**
```
"I'm sure it's a great way to socialize and stay active."
```

**Critique:**
```
âŒ Too generic â€” no actual information
âŒ Doesn't ask about user's experience
âŒ Doesn't offer to help
âŒ Lacks engagement
```

**v2 (Refined):**
```
"That's great! Table tennis requires quick reflexes and 
hand-eye coordination. Have you played before, or are 
you looking to learn? I can share tips or help you find 
local clubs!"
```

### Example: Code Optimization

**Task:** Sum of 1 to N

**v1:** O(n) loop â€” slow
```python
def sum(n):
    res = 0
    for i in range(n + 1):
        res += i
    return res
```

**Critique:** "Brute force. Use n(n+1)/2 formula."

**v2:** O(1) formula â€” instant
```python
def sum(n):
    return n * (n + 1) // 2
```

### When to Use

| Perfect For           | Skip For       |
|-----------------------|----------------|
| Code optimization     | Simple lookups |
| Writing polish        | Time-critical  |
| Quality-critical work | Basic queries  |
| Complex analysis      | High volume    |

---

## 5. Rephrase and Respond (RaR): Clarify Before Answering

### The Problem

Users write ambiguous, unclear, or poorly-phrased questions. AI guesses wrong.

### The Solution

**Have AI rephrase the question first, THEN answer.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RaR PROCESS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Original Question                                         â”‚
â”‚         â†“                                                   â”‚
â”‚   REPHRASE: Clarify and expand the question                 â”‚
â”‚         â†“                                                   â”‚
â”‚   RESPOND: Answer the clearer version                       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Real Example

**Original Question:**
```
"Take the last letters of the words in 'Edgar Bob' and concatenate them."
```

This is confusing! Let's use RaR:

**Step 1: Rephrase**
```
"Can you identify and extract the final letters in both words 
that form 'Edgar Bob' and then join them together in the order 
they appear?"
```

**Step 2: Respond**
```
The last letters are:
- "Edgar" â†’ "r"
- "Bob" â†’ "b"

Concatenated: "rb"
```

### One-Step vs Two-Step RaR

**One-Step (Single Prompt):**
```
[QUESTION]

Rephrase, expand, and respond.
```

**Two-Step (Separate LLMs):**
```
LLM 1 (Rephrasing): Clarifies the question
         â†“
LLM 2 (Responding): Answers the clarified question
```

Two-step is more accurate but slower.

### Combining RaR with CoT

RaR works even better with Chain-of-Thought:

```
[QUESTION]

First, rephrase this question for clarity.
Then, think through it step by step.
Finally, provide your answer.
```

### When to Use RaR

| Perfect For          | Skip For        |
|----------------------|-----------------|
| Ambiguous questions  | Clear questions |
| Complex instructions | Simple facts    |
| Non-native speakers  | Quick lookups   |
| Technical jargon     | Casual chat     |

### Limitations

- May struggle with very complex tasks (e.g., deciphering Chinese idioms)
- Poor training examples can lead to incorrect answers
- Requires careful question construction

### Copy-Paste Template

```
[YOUR QUESTION]

Before answering:
1. Rephrase this question for maximum clarity
2. Expand any ambiguous terms
3. Then provide your answer to the clarified question
```

---

## 6. Chain-of-Verification (CoVe): Self-Check for Accuracy

### The Problem

AI confidently states wrong facts. It doesn't double-check itself.

### The Solution

**Make AI verify its own answers with specific questions.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CoVe PROCESS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   1. INITIAL RESPONSE â†’ Draft an answer                     â”‚
â”‚         â†“                                                   â”‚
â”‚   2. PLAN VERIFICATIONS â†’ Create fact-check questions       â”‚
â”‚         â†“                                                   â”‚
â”‚   3. EXECUTE VERIFICATIONS â†’ Answer each question           â”‚
â”‚         â†“                                                   â”‚
â”‚   4. FINAL RESPONSE â†’ Corrected, verified answer            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Real Example

**Query:** "Name some politicians who were born in New York, New York."

**Step 1: Initial Response (May Have Errors)**
```
Politicians born in NY, New York:
1. Hillary Clinton
2. Donald Trump
3. Michael Bloomberg
```

**Step 2: Plan Verification Questions**
```
- Where was Hillary Clinton born?
- Where was Donald Trump born?
- Where was Michael Bloomberg born?
```

**Step 3: Execute Verifications**
```
âœ— Hillary Clinton â†’ Born in Chicago, Illinois
âœ“ Donald Trump â†’ Born in Queens, NY
âœ— Michael Bloomberg â†’ Born in Boston, Massachusetts
```

**Step 4: Final Verified Response**
```
Politicians actually born in NY, New York:
1. Donald Trump - Queens, NY âœ“
2. Alexandria Ocasio-Cortez - Bronx, NY âœ“
```

### The "Factored" Approach

CoVe uses a "factored" approach to prevent error propagation:

```
Instead of:
  "Verify all my facts" (vague)

CoVe does:
  Q1: "Where was Hillary Clinton born?" â†’ Chicago âœ—
  Q2: "Where was Donald Trump born?" â†’ Queens, NY âœ“
  Q3: "Where was Bloomberg born?" â†’ Boston âœ—
```

Each verification is independent, preventing one error from affecting others.

### When to Use CoVe

| Perfect For        | Skip For         |
|--------------------|------------------|
| Factual claims     | Opinions         |
| List-based answers | Creative writing |
| Historical data    | Brainstorming    |
| Biographical info  | Casual chat      |

### Limitations

- Reduces but doesn't eliminate errors
- Better for factual errors than reasoning errors
- Adds computational cost (longer outputs)
- Limited by model's knowledge

### Copy-Paste Template

```
[YOUR QUESTION]

After your initial answer:
1. List verification questions for each fact you stated
2. Answer each verification question independently
3. Provide a corrected final answer based on your verification
```

---

## 7. Chain of Natural Language Inferencing (CoNLI): Kill Hallucinations

### The Problem

AI makes up facts. It "hallucinates" â€” generates plausible-sounding but wrong information.

### The Solution

**A two-phase system that detects AND fixes hallucinations.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CoNLI FRAMEWORK                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           PHASE 1: DETECTION AGENT                    â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  S1: SELECT â†’ Break into hypotheses (claims)          â”‚   â”‚
â”‚  â”‚  S2: SENTENCE-LEVEL â†’ Check each sentence             â”‚   â”‚
â”‚  â”‚  S3: ENTITY-LEVEL â†’ Check names, numbers, dates       â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           PHASE 2: MITIGATION AGENT                   â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  Source Texts + Generated Response + Instructions    â”‚   â”‚
â”‚  â”‚              â†“                                        â”‚   â”‚
â”‚  â”‚  Fix or remove hallucinated content                   â”‚   â”‚
â”‚  â”‚  Preserve fluency and coherence                       â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Detection Works

**NLI (Natural Language Inference) Classification:**

| Label | Meaning | Action |
|-------|---------|--------|
| **Entailment** | Claim supported by source | Keep âœ“ |
| **Contradiction** | Claim conflicts with source | Fix! |
| **Neutral** | Can't determine | Flag for review |

### Real Example

**Source Text:**
```
"The Corner Brook Swim Club will host a meet. All swimmers must 
be members in good standing with SNC/SNL. Events are time finals."
```

**AI Generated (with hallucinations):**
```
"All swimmers must be members with SPCA/SNL. Events are speed finals."
```

**Detection:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Claim                    â”‚ Source Says    â”‚ Status         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  "members with SPCA/SNL"  â”‚ "SNC/SNL"      â”‚  WRONG         â”‚
â”‚  "speed finals"           â”‚ "time finals"  â”‚  WRONG         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mitigation (Fixed Output):**
```
"All swimmers must be members with SNC/SNL. Events are time finals."
```

### Chain-of-Thought in CoNLI

For each flagged claim, CoNLI reasons through:

```
Claim: "swimmers must be members with SPCA/SNL"
Premise Reference: Source says "SNC/SNL"
Reasoning: The premise mentions "SNC" but response says "SPCA"
Conclusion: CONTRADICTION â†’ Hallucination detected
```

### When to Use CoNLI

| Perfect For             | Skip For         |
|-------------------------|------------------|
| RAG applications        | Creative writing |
| Document summarization  | Opinions         |
| High-stakes content     | Casual chat      |
| Medical/legal/financial | Short responses  |

### Limitations

- May miss some hallucinations (only catches ungrounded ones)
- Depends on LLM accuracy for detection
- Post-processes rather than prevents
- Less effective for brief responses

---

## Comparison: All 7 Techniques

| Technique                 | Speed        | Accuracy    | Best Use Case        |
|---------------------------|--------------|-------------|----------------------|
| **Chain-of-Thought**      | âš¡ Fast       | â­â­â­         | Math, logic          |
| **ReAct**                 | ğŸ¢ Slow      | â­â­â­â­        | Research, facts      |
| **Skeleton-of-Thought**   | âš¡âš¡ Fastest   | â­â­â­         | Long answers         |
| **Self-Refine**           | ğŸ¢ Slow      | â­â­â­â­        | Quality writing      |
| **Rephrase & Respond**    | âš¡ Fast       | â­â­â­â­        | Unclear questions    |
| **Chain-of-Verification** | ğŸ¢ Slow      | â­â­â­â­        | Fact-checking        |
| **CoNLI**                 | ğŸ¢ğŸ¢ Slowest | â­â­â­â­â­       | Anti-hallucination   |

### Decision Flowchart

```
START
  â”‚
  â”œâ”€ Question unclear or ambiguous?
  â”‚     YES â†’ Rephrase and Respond (RaR)
  â”‚
  â”œâ”€ Need step-by-step reasoning?
  â”‚     YES â†’ Chain-of-Thought (CoT)
  â”‚
  â”œâ”€ Need current/verified facts?
  â”‚     YES â†’ ReAct
  â”‚
  â”œâ”€ Need long answers fast?
  â”‚     YES â†’ Skeleton-of-Thought (SoT)
  â”‚
  â”œâ”€ Need highest quality output?
  â”‚     YES â†’ Self-Refine
  â”‚
  â”œâ”€ Need to verify factual claims?
  â”‚     YES â†’ Chain-of-Verification (CoVe)
  â”‚
  â”œâ”€ Need to eliminate hallucinations?
  â”‚     YES â†’ CoNLI
  â”‚
  â””â”€ Simple question?
        YES â†’ Standard prompting
```

---

## Combining Techniques

The real power comes from **stacking** techniques:

### RaR + CoT
```
1. Rephrase the question for clarity
2. Think step by step through the clearer question
```

### ReAct + CoVe
```
1. Use ReAct to gather facts
2. Use CoVe to verify each fact
```

### SoT + Self-Refine + CoNLI
```
1. SoT for fast initial draft
2. Self-Refine to improve quality
3. CoNLI to fact-check final output
```

### The Ultimate Stack (for critical tasks)
```
1. RaR â†’ Clarify the question
2. CoT â†’ Reason step by step
3. Self-Refine â†’ Improve the answer
4. CoVe â†’ Verify key facts
5. CoNLI â†’ Check for hallucinations
```

---

## Quick Reference: Copy-Paste Templates

### 1. Chain-of-Thought
```
[QUESTION]
Think through this step by step.
```

### 2. ReAct
```
[QUESTION]
Use this format:
THINK: [reasoning]
ACT: Search["query"] or Calculate["expression"]
OBSERVE: [results]
ANSWER: [final answer]
```

### 3. Skeleton-of-Thought
```
Create ONLY a skeleton (3-5 words per point, 3-10 points).
Question: [QUESTION]
```

### 4. Self-Refine
```
[QUESTION]
1. Provide initial answer
2. Critique it (what's wrong?)
3. Provide improved answer
```

### 5. Rephrase and Respond
```
[QUESTION]
First, rephrase this question for clarity.
Then, answer the clarified question.
```

### 6. Chain-of-Verification
```
[QUESTION]
1. Provide initial answer
2. Create verification questions for each fact
3. Answer each verification question
4. Provide corrected final answer
```

### 7. CoNLI
```
Source: [SOURCE TEXT]
Response: [AI RESPONSE]

For each claim:
1. Classify as SUPPORTED/CONTRADICTED/NEUTRAL
2. If contradicted, explain what's wrong
3. Provide corrected version
```

---

## Key Takeaways

| # | Technique                 | One-Liner                        |
|---|---------------------------|----------------------------------|
| 1 | **Chain-of-Thought**      | "Think step by step"             |
| 2 | **ReAct**                 | Think â†’ Act â†’ Observe â†’ Repeat   |
| 3 | **Skeleton-of-Thought**   | Outline â†’ Expand in parallel     |
| 4 | **Self-Refine**           | Generate â†’ Critique â†’ Improve    |
| 5 | **Rephrase & Respond**    | Clarify question â†’ Then answer   |
| 6 | **Chain-of-Verification** | Answer â†’ Verify facts â†’ Correct  |
| 7 | **CoNLI**                 | Detect hallucinations â†’ Fix them |

---

## Final Thought

Most people use AI at 20% of its potential. These 7 techniques unlock the other 80%.

Start with **Chain-of-Thought** (easiest) and **Rephrase and Respond** (most overlooked). Then add the others as needed.

The best AI users don't just ask questions. They engineer prompts.

Now you know how.

---

## References

- Wei et al. (2022) "Chain-of-Thought Prompting Elicits Reasoning"
- Yao et al. (2023) "ReAct: Synergizing Reasoning and Acting"
- Ning et al. (2023) "Skeleton-of-Thought: Parallel Decoding"
- Madaan et al. (2023) "Self-Refine: Iterative Refinement"
- Deng et al. (2023) "Rephrase and Respond: Let LLMs Ask Better Questions"
- Dhuliawala et al. (2023) "Chain-of-Verification Reduces Hallucination"
- Lei et al. (2023) "Chain of NLI for Reducing LLM Hallucinations"
- Analytics Vidhya â€” Advanced Prompt Engineering Course


---

*Which technique will you try first? Drop a comment below! at Linkedein *

* #PromptEngineering #AI #ChatGPT #LLM #ChainOfThought #ReAct #SelfRefine #CoNLI *
