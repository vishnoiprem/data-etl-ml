{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c7b5ff",
   "metadata": {},
   "source": [
    "# Energy Consumption Prediction - Step-by-Step Guide\n",
    "\n",
    "This notebook provides a comprehensive guide to predict Total Energy Consumption using various machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11df2b6f",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "We start by importing the necessary libraries for data manipulation, visualization, and model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29899d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.1-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.1)\n",
      "Using cached xgboost-2.1.1-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (2.1 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d97fdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T12:07:40.834798Z",
     "start_time": "2024-09-29T12:07:33.687933Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a7478",
   "metadata": {},
   "source": [
    "## Step 2: Load and Explore the Dataset\n",
    "Read the Excel file and explore the dataset to understand its structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b014c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTR</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>GDP</th>\n",
       "      <th>EPROD</th>\n",
       "      <th>CAPF</th>\n",
       "      <th>CAPS</th>\n",
       "      <th>EITNS</th>\n",
       "      <th>COAL_ECONS</th>\n",
       "      <th>NATG_ECONS</th>\n",
       "      <th>OIL_ECONS</th>\n",
       "      <th>REW_ECONS</th>\n",
       "      <th>TOTAL_ECONS</th>\n",
       "      <th>ELEC_CONS</th>\n",
       "      <th>POP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brunei Darussalam</td>\n",
       "      <td>BRN</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.976922</td>\n",
       "      <td>12.644170</td>\n",
       "      <td>36.661699</td>\n",
       "      <td>0.641115</td>\n",
       "      <td>4.089095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>0.022379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061915</td>\n",
       "      <td>1.779</td>\n",
       "      <td>2.423676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brunei Darussalam</td>\n",
       "      <td>BRN</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.493136</td>\n",
       "      <td>12.922198</td>\n",
       "      <td>41.314294</td>\n",
       "      <td>0.641913</td>\n",
       "      <td>4.060988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031788</td>\n",
       "      <td>0.025875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057663</td>\n",
       "      <td>1.953</td>\n",
       "      <td>2.345748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brunei Darussalam</td>\n",
       "      <td>BRN</td>\n",
       "      <td>1997</td>\n",
       "      <td>-3.679156</td>\n",
       "      <td>12.327908</td>\n",
       "      <td>35.493067</td>\n",
       "      <td>0.654120</td>\n",
       "      <td>4.130741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035863</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061666</td>\n",
       "      <td>2.234</td>\n",
       "      <td>2.266444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brunei Darussalam</td>\n",
       "      <td>BRN</td>\n",
       "      <td>1998</td>\n",
       "      <td>-2.713190</td>\n",
       "      <td>12.310974</td>\n",
       "      <td>33.805310</td>\n",
       "      <td>0.627312</td>\n",
       "      <td>4.075556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030973</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055774</td>\n",
       "      <td>2.324</td>\n",
       "      <td>2.190603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brunei Darussalam</td>\n",
       "      <td>BRN</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.880167</td>\n",
       "      <td>12.442648</td>\n",
       "      <td>21.380018</td>\n",
       "      <td>0.644307</td>\n",
       "      <td>3.976667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038454</td>\n",
       "      <td>0.027352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065806</td>\n",
       "      <td>2.260</td>\n",
       "      <td>2.130189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              COUNTR Country Code  Year       GDP      EPROD       CAPF  \\\n",
       "0  Brunei Darussalam          BRN  1995  1.976922  12.644170  36.661699   \n",
       "1  Brunei Darussalam          BRN  1996  0.493136  12.922198  41.314294   \n",
       "2  Brunei Darussalam          BRN  1997 -3.679156  12.327908  35.493067   \n",
       "3  Brunei Darussalam          BRN  1998 -2.713190  12.310974  33.805310   \n",
       "4  Brunei Darussalam          BRN  1999  0.880167  12.442648  21.380018   \n",
       "\n",
       "       CAPS     EITNS  COAL_ECONS  NATG_ECONS  OIL_ECONS  REW_ECONS  \\\n",
       "0  0.641115  4.089095         0.0    0.039536   0.022379        0.0   \n",
       "1  0.641913  4.060988         0.0    0.031788   0.025875        0.0   \n",
       "2  0.654120  4.130741         0.0    0.035863   0.025803        0.0   \n",
       "3  0.627312  4.075556         0.0    0.030973   0.024801        0.0   \n",
       "4  0.644307  3.976667         0.0    0.038454   0.027352        0.0   \n",
       "\n",
       "   TOTAL_ECONS  ELEC_CONS       POP  \n",
       "0     0.061915      1.779  2.423676  \n",
       "1     0.057663      1.953  2.345748  \n",
       "2     0.061666      2.234  2.266444  \n",
       "3     0.055774      2.324  2.190603  \n",
       "4     0.065806      2.260  2.130189  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Final_energy_data_28.9.xlsx'\n",
    "data = pd.read_excel(file_path, sheet_name='Data')\n",
    "\n",
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d07dbcd",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing\n",
    "Clean the dataset by handling missing values and selecting relevant features for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a45196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "data_clean = data.dropna()\n",
    "\n",
    "# Select features and target\n",
    "features = data_clean[['GDP', 'EPROD', 'CAPF', 'CAPS', 'EITNS', 'COAL_ECONS', 'NATG_ECONS', 'OIL_ECONS', 'REW_ECONS', 'ELEC_CONS', 'POP']]\n",
    "target = data_clean['TOTAL_ECONS']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d118add",
   "metadata": {},
   "source": [
    "## Step 4: Train a Random Forest Regressor Model\n",
    "We start by training a Random Forest Regressor model to predict the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf3203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor - MSE: 0.03382245254354937, MAE: 0.11316684768461524, R2: 0.9913370193744432\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest Regressor - MSE: {mse_rf}, MAE: {mae_rf}, R2: {r2_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c35e3",
   "metadata": {},
   "source": [
    "## Step 5: Try Different Models for Comparison\n",
    "We will try different models such as Linear Regression, SVR, and XGBoost to see if any model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a97734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 3.292426635236672e-07, MAE: 7.973435380128092e-05, R2: 0.9999999156707275\n",
      "SVR - MSE: 0.7474954440386951, MAE: 0.5550110927519538, R2: 0.8085431994897073\n",
      "XGBoost - MSE: 0.036458899398762186, MAE: 0.11932420237402698, R2: 0.9906617434464894\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "print(f'Linear Regression - MSE: {mse_linear}, MAE: {mae_linear}, R2: {r2_linear}')\n",
    "\n",
    "# Support Vector Regressor (SVR) Model\n",
    "svr_model = SVR()\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "print(f'SVR - MSE: {mse_svr}, MAE: {mae_svr}, R2: {r2_svr}')\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f'XGBoost - MSE: {mse_xgb}, MAE: {mae_xgb}, R2: {r2_xgb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ea8b7",
   "metadata": {},
   "source": [
    "## Step 6: Feature Importance Analysis\n",
    "Identify which features are most important for the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "347b16e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance analysis using Random Forest (can switch to other models)\n",
    "feature_importances = rf_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': feature_importances})\n",
    "importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "importance_df.plot(kind='barh', x='Feature', y='Importance', title='Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba864dc",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "Based on the results, we can select the best model and further refine it by hyperparameter tuning or additional feature engineering. \n",
    "\n",
    "If needed, explore other models or advanced techniques such as neural networks for further improvements.\n",
    "\n",
    "so i can say"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e094f69",
   "metadata": {},
   "source": [
    "## networks\n",
    "Lets try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d09e7d",
   "metadata": {},
   "source": [
    "##Key Takeaways\n",
    "Linear Regression achieved near-perfect performance with an R² score of 1.000, suggesting it fits the data exceptionally well.\n",
    "XGBoost (Optimized) also performed very well, with an R² of 0.995, making it a robust choice.\n",
    "Support Vector Regressor had a relatively lower performance compared to the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee6c8a",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "## Linear Regression achieved near-perfect performance with an R² score of 1.000, suggesting it fits the data exceptionally well.\n",
    "\n",
    "## XGBoost (Optimized) also performed very well, with an R² of 0.995, making it a robust choice.\n",
    "\n",
    "## Support Vector Regressor had a relatively lower performance compared to the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8181fab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.2-cp311-cp311-macosx_10_15_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.66.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Using cached rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.12.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/vishnoiprem/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.16.2-cp311-cp311-macosx_10_15_x86_64.whl (259.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.6/259.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.2-cp311-cp311-macosx_10_9_universal2.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-macosx_10_9_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "Downloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl (389 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp311-cp311-macosx_10_9_universal2.whl (523 kB)\n",
      "Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, rich, keras, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.27.2\n",
      "    Uninstalling protobuf-5.27.2:\n",
      "      Successfully uninstalled protobuf-5.27.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.2 h5py-3.12.1 keras-3.5.0 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.4.0 optree-0.12.1 protobuf-4.25.5 rich-13.8.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 19:24:08.233102: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "# Import necessary libraries for building neural networks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f8f1a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishnoiprem/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Model Creation\n",
    "\n",
    "# Define the neural network architecture\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Input layer with 64 neurons\n",
    "nn_model.add(Dense(32, activation='relu'))  # Hidden layer with 32 neurons\n",
    "nn_model.add(Dense(16, activation='relu'))  # Hidden layer with 16 neurons\n",
    "nn_model.add(Dense(1, activation='linear'))  # Output layer for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e2374a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.0757 - mae: 1.3149 - val_loss: 1.1654 - val_mae: 0.8977\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0309 - mae: 0.8050 - val_loss: 0.6036 - val_mae: 0.5325\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6896 - mae: 0.5728 - val_loss: 0.5949 - val_mae: 0.5739\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5819 - mae: 0.5370 - val_loss: 0.5017 - val_mae: 0.4821\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4406 - mae: 0.4566 - val_loss: 0.6328 - val_mae: 0.5654\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5230 - mae: 0.4871 - val_loss: 0.4585 - val_mae: 0.4213\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3061 - mae: 0.3463 - val_loss: 0.4491 - val_mae: 0.4224\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2911 - mae: 0.3433 - val_loss: 0.4235 - val_mae: 0.4149\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3253 - mae: 0.3687 - val_loss: 0.4138 - val_mae: 0.4183\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3512 - mae: 0.3747 - val_loss: 0.5070 - val_mae: 0.4406\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3202 - mae: 0.3910 - val_loss: 0.3834 - val_mae: 0.3898\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3360 - mae: 0.3574 - val_loss: 0.3743 - val_mae: 0.4016\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3664 - mae: 0.3829 - val_loss: 0.4214 - val_mae: 0.4117\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4835 - mae: 0.4499 - val_loss: 0.7658 - val_mae: 0.5370\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4899 - mae: 0.4411 - val_loss: 0.3275 - val_mae: 0.3686\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3190 - mae: 0.3664 - val_loss: 0.3833 - val_mae: 0.4170\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2812 - mae: 0.3073 - val_loss: 0.3045 - val_mae: 0.3590\n",
      "Epoch 18/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2489 - mae: 0.3020 - val_loss: 0.3227 - val_mae: 0.3518\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2529 - mae: 0.3148 - val_loss: 0.2970 - val_mae: 0.3640\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2314 - mae: 0.3004 - val_loss: 0.2968 - val_mae: 0.3471\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2919 - mae: 0.3239 - val_loss: 0.6324 - val_mae: 0.4879\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2308 - mae: 0.3513 - val_loss: 0.2477 - val_mae: 0.3507\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2230 - mae: 0.3043 - val_loss: 0.2239 - val_mae: 0.3165\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2225 - mae: 0.2723 - val_loss: 0.3278 - val_mae: 0.3729\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2289 - mae: 0.2863 - val_loss: 0.2878 - val_mae: 0.3525\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2115 - mae: 0.2828 - val_loss: 0.2565 - val_mae: 0.3535\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2056 - mae: 0.2969 - val_loss: 0.2547 - val_mae: 0.3453\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1930 - mae: 0.2683 - val_loss: 0.2333 - val_mae: 0.3315\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1897 - mae: 0.2751 - val_loss: 0.2747 - val_mae: 0.3498\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1913 - mae: 0.2527 - val_loss: 0.2082 - val_mae: 0.3119\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1538 - mae: 0.2325 - val_loss: 0.2117 - val_mae: 0.3105\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1384 - mae: 0.2103 - val_loss: 0.2061 - val_mae: 0.3055\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1313 - mae: 0.2126 - val_loss: 0.2088 - val_mae: 0.3062\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1718 - mae: 0.2538 - val_loss: 0.1996 - val_mae: 0.3001\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1238 - mae: 0.2152 - val_loss: 0.3307 - val_mae: 0.3710\n",
      "Epoch 36/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1713 - mae: 0.2515 - val_loss: 0.1452 - val_mae: 0.2651\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1119 - mae: 0.2133 - val_loss: 0.1410 - val_mae: 0.2649\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1073 - mae: 0.2205 - val_loss: 0.1401 - val_mae: 0.2579\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0983 - mae: 0.1996 - val_loss: 0.1984 - val_mae: 0.2786\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1219 - mae: 0.2278 - val_loss: 0.1305 - val_mae: 0.2583\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0731 - mae: 0.1676 - val_loss: 0.1422 - val_mae: 0.2480\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0803 - mae: 0.1725 - val_loss: 0.1224 - val_mae: 0.2409\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0848 - mae: 0.1751 - val_loss: 0.1150 - val_mae: 0.2395\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0660 - mae: 0.1644 - val_loss: 0.1999 - val_mae: 0.2802\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1358 - mae: 0.2418 - val_loss: 0.1112 - val_mae: 0.2374\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0634 - mae: 0.1759 - val_loss: 0.1430 - val_mae: 0.2445\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0510 - mae: 0.1453 - val_loss: 0.0929 - val_mae: 0.2249\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0771 - mae: 0.1832 - val_loss: 0.0900 - val_mae: 0.2205\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0620 - mae: 0.1619 - val_loss: 0.0945 - val_mae: 0.2245\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1186 - mae: 0.1856 - val_loss: 0.0926 - val_mae: 0.2172\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0960 - mae: 0.1730 - val_loss: 0.1164 - val_mae: 0.2194\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1819 - mae: 0.2057 - val_loss: 0.1139 - val_mae: 0.2175\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1822 - mae: 0.1905 - val_loss: 0.2049 - val_mae: 0.2739\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1855 - mae: 0.2078 - val_loss: 0.0977 - val_mae: 0.2545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1958 - mae: 0.2316 - val_loss: 0.1981 - val_mae: 0.3183\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2559 - mae: 0.2426 - val_loss: 0.1991 - val_mae: 0.3172\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1439 - mae: 0.2414 - val_loss: 0.1012 - val_mae: 0.2233\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0728 - mae: 0.1788 - val_loss: 0.0734 - val_mae: 0.1935\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0489 - mae: 0.1563 - val_loss: 0.0937 - val_mae: 0.1925\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0544 - mae: 0.1548 - val_loss: 0.0642 - val_mae: 0.1748\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1270 - val_loss: 0.0615 - val_mae: 0.1861\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1298 - val_loss: 0.0480 - val_mae: 0.1649\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0300 - mae: 0.1153 - val_loss: 0.0497 - val_mae: 0.1728\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0240 - mae: 0.1055 - val_loss: 0.0473 - val_mae: 0.1634\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0264 - mae: 0.1111 - val_loss: 0.0720 - val_mae: 0.1436\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0325 - mae: 0.1074 - val_loss: 0.0414 - val_mae: 0.1438\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mae: 0.0815 - val_loss: 0.0454 - val_mae: 0.1393\n",
      "Epoch 68/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0183 - mae: 0.0879 - val_loss: 0.0406 - val_mae: 0.1523\n",
      "Epoch 69/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0194 - mae: 0.0940 - val_loss: 0.0394 - val_mae: 0.1476\n",
      "Epoch 70/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0197 - mae: 0.0953 - val_loss: 0.0399 - val_mae: 0.1465\n",
      "Epoch 71/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0774 - val_loss: 0.0384 - val_mae: 0.1463\n",
      "Epoch 72/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - mae: 0.0835 - val_loss: 0.0478 - val_mae: 0.1326\n",
      "Epoch 73/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0179 - mae: 0.0863 - val_loss: 0.0780 - val_mae: 0.1533\n",
      "Epoch 74/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0194 - mae: 0.0923 - val_loss: 0.0639 - val_mae: 0.1373\n",
      "Epoch 75/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0291 - mae: 0.1109 - val_loss: 0.0407 - val_mae: 0.1481\n",
      "Epoch 76/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0874 - val_loss: 0.0369 - val_mae: 0.1451\n",
      "Epoch 77/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0149 - mae: 0.0898 - val_loss: 0.0343 - val_mae: 0.1378\n",
      "Epoch 78/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - mae: 0.0697 - val_loss: 0.0528 - val_mae: 0.1318\n",
      "Epoch 79/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0720 - val_loss: 0.0663 - val_mae: 0.1422\n",
      "Epoch 80/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0237 - mae: 0.0973 - val_loss: 0.0331 - val_mae: 0.1358\n",
      "Epoch 81/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0728 - val_loss: 0.0374 - val_mae: 0.1382\n",
      "Epoch 82/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0639 - val_loss: 0.0378 - val_mae: 0.1265\n",
      "Epoch 83/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - mae: 0.0557 - val_loss: 0.0385 - val_mae: 0.1499\n",
      "Epoch 84/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0158 - mae: 0.0923 - val_loss: 0.0306 - val_mae: 0.1312\n",
      "Epoch 85/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mae: 0.0845 - val_loss: 0.1309 - val_mae: 0.2234\n",
      "Epoch 86/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0312 - mae: 0.1128 - val_loss: 0.0329 - val_mae: 0.1365\n",
      "Epoch 87/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - mae: 0.0929 - val_loss: 0.0419 - val_mae: 0.1588\n",
      "Epoch 88/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mae: 0.0788 - val_loss: 0.0310 - val_mae: 0.1205\n",
      "Epoch 89/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - mae: 0.0592 - val_loss: 0.0814 - val_mae: 0.1605\n",
      "Epoch 90/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mae: 0.0888 - val_loss: 0.0316 - val_mae: 0.1336\n",
      "Epoch 91/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0241 - mae: 0.1041 - val_loss: 0.0356 - val_mae: 0.1416\n",
      "Epoch 92/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.0927 - val_loss: 0.0596 - val_mae: 0.1368\n",
      "Epoch 93/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0178 - mae: 0.0927 - val_loss: 0.0262 - val_mae: 0.1161\n",
      "Epoch 94/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mae: 0.0584 - val_loss: 0.0285 - val_mae: 0.1187\n",
      "Epoch 95/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - mae: 0.0568 - val_loss: 0.0284 - val_mae: 0.1168\n",
      "Epoch 96/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0572 - val_loss: 0.0342 - val_mae: 0.1175\n",
      "Epoch 97/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mae: 0.0554 - val_loss: 0.0268 - val_mae: 0.1188\n",
      "Epoch 98/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0645 - val_loss: 0.0261 - val_mae: 0.1101\n",
      "Epoch 99/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - mae: 0.0578 - val_loss: 0.0275 - val_mae: 0.1171\n",
      "Epoch 100/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0534 - val_loss: 0.0400 - val_mae: 0.1211\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = nn_model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=16, callbacks=[early_stopping], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bce300fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
    "mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d031df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - MSE: 0.01532171084057642, MAE: 0.09332506302774989, R²: 0.9960756339596784\n"
     ]
    }
   ],
   "source": [
    "print(f\"Neural Network - MSE: {mse_nn}, MAE: {mae_nn}, R²: {r2_nn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f430cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison with Neural Network:\n",
      "             Model       MSE       MAE        R²\n",
      "0  Neural Network  0.015322  0.093325  0.996076\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with the results to be added\n",
    "new_row = pd.DataFrame({'Model': ['Neural Network'], 'MSE': [mse_nn], 'MAE': [mae_nn], 'R²': [r2_nn]})\n",
    "\n",
    "# Concatenate the new row with the existing results DataFrame\n",
    "results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Display the updated results\n",
    "print(\"Model Performance Comparison with Neural Network:\\n\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72a6b4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishnoiprem/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,442</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,626,442\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,442</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,626,442\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define a basic CNN architecture\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # Assuming 10 classes in the dataset\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41fa896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishnoiprem/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m10,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,651</span> (119.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,651\u001b[0m (119.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,651</span> (119.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,651\u001b[0m (119.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Define a basic LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(10, 1)),  # 10 time steps with 1 feature\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00ed2815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_lstm: (200, 10, 11)\n",
      "Shape of X_test_lstm: (50, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "# Create sequences of 10 time steps\n",
    "time_steps = 10\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(time_steps, len(data)):\n",
    "        X.append(data[i-time_steps:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Use the scaler to transform the data first\n",
    "scaled_data = scaler.fit_transform(features)\n",
    "\n",
    "# Create sequences with 10 time steps\n",
    "X_lstm, y_lstm = create_sequences(scaled_data, time_steps)\n",
    "\n",
    "# Split the sequences into training and testing sets again\n",
    "split = int(0.8 * len(X_lstm))  # 80% for training, 20% for testing\n",
    "X_train_lstm, X_test_lstm = X_lstm[:split], X_lstm[split:]\n",
    "y_train_lstm, y_test_lstm = y_lstm[:split], y_lstm[split:]\n",
    "\n",
    "# Reshape the input data for the LSTM model\n",
    "print(\"Shape of X_train_lstm:\", X_train_lstm.shape)  # Should be (samples, 10, 11)\n",
    "print(\"Shape of X_test_lstm:\", X_test_lstm.shape)    # Should be (samples, 10, 11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0c971",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "The goal of this project is to predict Total Energy Consumption using various machine learning models, including a feedforward neural network and an LSTM network for sequential data. The dataset used includes multiple features such as GDP, energy production, and different forms of energy consumption. We explored different approaches, such as linear models and deep learning models, to find the best predictor of total energy consumption.\n",
    "\n",
    "## Key Steps and Results\n",
    "Data Preparation:\n",
    "\n",
    "The dataset was preprocessed by handling missing values and scaling the features.\n",
    "Features like GDP, EPROD, and various energy consumption metrics were selected to predict the target variable: Total Energy Consumption.\n",
    "Machine Learning Models Implemented:\n",
    "\n",
    "## Linear Regression: Provided a baseline for comparison with other models.\n",
    "Support Vector Regressor (SVR): Tried capturing non-linear relationships.\n",
    "Random Forest Regressor: Used for feature importance analysis and capturing non-linear patterns.\n",
    "XGBoost Regressor: A powerful gradient boosting model that achieved high accuracy.\n",
    "\n",
    "## Neural Network: Implemented a basic feedforward neural network.\n",
    "LSTM Network: Used for capturing temporal dependencies in the data. This model faced challenges due to shape mismatches, which were addressed through reshaping the data.\n",
    "Evaluation and Comparison:\n",
    "\n",
    "### The models were evaluated using metrics like Mean Squared Error (MSE), Mean Absolute Error (MAE), and R² score.\n",
    "The XGBoost model and Linear Regression model performed well, with high R² scores, indicating strong predictive power.\n",
    "Challenges Encountered:\n",
    "\n",
    "Issues with reshaping data for the LSTM network were resolved by modifying the input shape or adjusting the sequences.\n",
    "Compatibility issues with libraries like TensorFlow in the current environment hindered real-time LSTM visualization, but the necessary code was provided.\n",
    "Key Insights from the Project\n",
    "Feature Importance:\n",
    "\n",
    "## Natural Gas Consumption (NATG_ECONS) and Oil Consumption (OIL_ECONS) were found to be the most important features influencing total energy consumption, indicating a strong relationship between these variables.\n",
    "Model Comparison:\n",
    "\n",
    "The XGBoost model achieved the highest R² score, making it the best-performing model among all those tested.\n",
    "Linear Regression was a close contender, suggesting that a linear relationship exists between the features and the target variable.\n",
    "Neural Network Results:\n",
    "\n",
    "The feedforward neural network provided reasonable predictions, but the LSTM model faced shape-related issues, which required modifications to either the model or the input data.\n",
    "Recommendations\n",
    "Focus on the Best-Performing Model:\n",
    "\n",
    "## Use the XGBoost model for predicting total energy consumption, as it consistently achieved high accuracy.\n",
    "Explore additional feature engineering, such as creating new variables from existing features or combining related features to improve the model further.\n",
    "LSTM Model Enhancement:\n",
    "\n",
    "For future iterations, refine the LSTM model by creating time series sequences or increasing the time steps to better capture temporal dependencies.\n",
    "Deployment and Monitoring:\n",
    "\n",
    "##  Deploy the best-performing model and monitor its performance on real-world data. Set up regular retraining schedules to maintain accuracy over time.\n",
    "\n",
    "\n",
    "## Final Thoughts\n",
    "This project demonstrates the utility of machine learning and deep learning models in energy consumption prediction. \n",
    "\n",
    "\n",
    "By selecting the right features and models, it is possible to achieve high predictive performance, which can be valuable for energy management and planning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94cb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
