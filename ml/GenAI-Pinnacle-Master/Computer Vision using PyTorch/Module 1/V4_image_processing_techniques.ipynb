{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6b1cb2-65c6-46a0-860b-6f00d137f6e4",
   "metadata": {},
   "source": [
    "# Video 4: Image Processing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fa0e5-bbbe-45d1-ba28-e7e6c743e3fd",
   "metadata": {},
   "source": [
    "Hi and welcome to the first hands on video of this course. This is where things get interesting! In this video, we shall understand the process of applying filters on any given image. First, we need to import the required libraries for this video. Since the task in hand is to apply filters on images, we need to import the matplotlib library, followed by numpy and skimage. For those of you not familiar with Skimage, let me quickly help you understand its use cases. Skimage offers a variety of image processing tools, including filtering, morphology, segmentation, transformations, and exposure adjustments. It is well-suited for tasks such as feature extraction, image enhancement and object detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39888c17-c506-479f-bf11-fb17f9e6fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to install the library\n",
    "#pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7107b0-d86d-45b9-aac1-0107c6c2777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff53f41-8665-4104-bbad-b7f03cf3b691",
   "metadata": {},
   "source": [
    "### Images available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887dc1b-3c59-4cf8-9980-b2cb0b2bc019",
   "metadata": {},
   "source": [
    "Next, let's look at some sample images present in the scikit image library. Below is the code to obtain the the available images from the library. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c3393-7e09-4f5d-b93a-0662a6fe258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.data as data\n",
    "\n",
    "# List all attributes of the skimage.data module that are callable (i.e., functions)\n",
    "available_images = [name for name in dir(data) if callable(getattr(data, name))]\n",
    "\n",
    "print(available_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df8775-22f5-4ff3-ad08-a296f6c035d7",
   "metadata": {},
   "source": [
    "For our purpose let's import a couple of images namely \"camera\" and \"brick\". Feel free to try  this exercise with other images as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf381ebc-959c-4543-9ec3-05189a9b5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = (\n",
    "    'brick',\n",
    "    'camera',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385e6e2-0a83-4317-80bb-e261c1c760cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.data import camera, brick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130fada7-51ec-4ca1-812c-ce1e03f37f6d",
   "metadata": {},
   "source": [
    "Once we've imported the image, let's view the shape and the pixels present in the image in NumPy array format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08faf5b2-ebaa-4c36-9ee3-ea58059fadaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b21b61-1e9b-40ac-b4c6-e22f2a9bef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d8d9d-c669-423c-b19a-271004887760",
   "metadata": {},
   "source": [
    "The top left pixel has a value of 200 while the right bottom pixel has a value of 149 and the resolution of the image is 512 x 512."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3c39a-0384-40ab-912b-eab9d39b843b",
   "metadata": {},
   "source": [
    "Next, let's view the image we imported that is \"camera\". The code is very simple as shown below. Let's run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072295b-abe1-44ee-8057-7931f4e76f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ski.io.imshow(camera());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b3144-8964-4756-b43a-2f93a556057f",
   "metadata": {},
   "source": [
    "Similarly let's also view the brick image we just imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e54ac-558c-408d-9245-9b2087d49c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ski.io.imshow(brick());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6078ac-1e81-47fa-8b36-2a64133e5ae8",
   "metadata": {},
   "source": [
    "# Custom kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6dc1b5-3401-450b-ad1f-1cc4256ab66f",
   "metadata": {},
   "source": [
    "Now that we've successfully imported the images, it time to apply filters to them. Some of the most basic filters in computer vision include the horizontal and vertical filteres. Let first define the vertical filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028dd190-9ab1-4d39-b656-fd7b7d1d3078",
   "metadata": {},
   "source": [
    "#### Vertical Kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba2b9f-98bb-4fbc-b01b-81b753a0f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_filter = [[-5, 0, 5], \n",
    "        [-0.5, 0, 0.5],\n",
    "        [-5, 0, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e8ca82-20fb-497e-bd4f-6b9d0f505e26",
   "metadata": {},
   "source": [
    "Here in our manual vertical filter. As you can observe the size of the filter is 3x3. Notice how we've used the values of -5 and 5 at the corners of the filter. These are strong weights which help accentuate the differences in the image. Also notice how the middle column has 0's in it. This is crucial to highlight the vertical portions of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02266b67-d2e6-4c55-8b02-a835fa140a08",
   "metadata": {},
   "source": [
    "Next lets define the apply filter function for our image. This functionn takes an image and a convolutionalfilterl as input and returns the output of the convolutionn. It first calculates thedimensions of the  imag and the filter, and, then initializes an output imagewith 0 pixel values ofh the same siz as the inpute. The functionthen slidess overthe image as shown in the previous video and multiplies the values of the filter with the respective positons of the image to generate the values for the resultant output. Note that this function will only work when both the image and the kernel have a square shape. That means, the length and the width is the same.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a1d28-5ce2-454b-a629-dce5c6b93737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(image, v_filter):\n",
    "    \n",
    "    # Get dimensions of the image\n",
    "    width = image.shape[1]\n",
    "    kw = len(v_filter)\n",
    "\n",
    "    # Prepare output image\n",
    "    output = [[0] * width for _ in range(width)]\n",
    "\n",
    "    # Apply filter to the image\n",
    "    for y in range(1, width - 1):\n",
    "        for x in range(1, width - 1):\n",
    "            sum_ = 0\n",
    "            for v_filter_y in range(kw):\n",
    "                for v_filter_x in range(kw):\n",
    "                    val = image[y + v_filter_y - 1][x + v_filter_x - 1]\n",
    "                    sum_ += v_filter[v_filter_y][v_filter_x] * val\n",
    "\n",
    "            output[y][x] = sum_\n",
    "\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4513f-1db6-46e0-a58d-c41c51c86102",
   "metadata": {},
   "source": [
    "##### Vertical Kernal for the \"Camera\" image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f83d5-9872-4f25-8943-82c1d65ce45e",
   "metadata": {},
   "source": [
    "Now that we've defined the function, it's time to apply it on our image and take a look at the output. Let's apply it first on the camera image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab1980-6bd8-4f89-ab25-de3165635267",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = apply_filter(camera(), kernel)\n",
    "ski.io.imshow(output, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7be621-7edb-482d-ada0-3452ced2453f",
   "metadata": {},
   "source": [
    "Take a look at the output, the image named camera displayed over here, shows the effect of applying a vertical edge-detection filter on a photograph. This type of filter emphasizes vertical lines and transitions in pixel values across the image. As a result, vertical features such as the man's profile, the tripod, and elements in the background are prominently highlighted, while horizontal features are less distinct. With that let's quickly apply the same vertical filter to the next image that is brick."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcebdb5-9d19-406f-b00b-3d3fcb143220",
   "metadata": {},
   "source": [
    "##### Vertical Kernal for the \"Brick\" image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e81172-acbe-43ac-a6f5-e7d32e8ef212",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = apply_filter(brick(), v_filter)\n",
    "ski.io.imshow(output, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac7d4e-8ccf-4709-94f7-a287ab38e0ff",
   "metadata": {},
   "source": [
    "Take a look at the output for the brick image. Here, the filter highlights the vertical mortar joints between bricks, making them appear as bright lines on a darker background. Horizontal features are subdued, emphasizing vertical structures. The impact of a vertical filter is much more evident here right? Let's quickly apply a horizontal filter to both these images and view the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbcddf3-9dad-48fb-adb2-a975618298e2",
   "metadata": {},
   "source": [
    "#### Horizontal Kernal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329dedb-d6d0-4988-8544-07f4f6a86123",
   "metadata": {},
   "source": [
    "Take a look at the below horizontal filter. \n",
    "In this filter notice how we've used larger values across the middle row to emphasize horizontal edges\n",
    ". Rest of the code remains the exact same as earlier. Let's run this code and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce4259-5a81-475b-9f5a-cdd3054386aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_filter = [[-0.5, -5, -0.5], \n",
    "        [0, 0, 0],\n",
    "        [0.5, 5, 0.5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074f26ac-c2ff-4d44-935f-cd009d64b94f",
   "metadata": {},
   "source": [
    "##### Horizontal Kernal for the \"Camera\" image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8586a1e-4951-41de-b76a-8d23b54688af",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = apply_filter(camera(), h_filter)\n",
    "ski.io.imshow(output, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86fcfaf-99cd-420d-b255-a7a59db35518",
   "metadata": {},
   "source": [
    "##### Horizontal Kernal for the \"Brick\" image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba168e11-468f-4c61-a7e3-de7b4a680aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = apply_filter(brick(), h_filter)\n",
    "ski.io.imshow(output, cmap=plt.cm.gray);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f36db588-1360-496d-96f7-0f7c547f76c2",
   "metadata": {},
   "source": [
    "On applying a horizontal filter you saw how the man's shoulders, and other horizontal lines in background stand out as bright lines.\n",
    "In case of the output for the brick image with a horizontal filter, we can see that the horizontal mortar joints between the bricks are emphasized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428e5df-7aa6-4526-a615-4b5dd13e34bc",
   "metadata": {},
   "source": [
    "Now with that, we've clearly understood how filters can extract specific information from images and the rile of the convolution layers in doing so. Don't forget to experiment with different images and filters and have a look at the transformed images. We've also attached a reading material for you with the different values for each filter to make things easier! In the next video let's learn a few more nuances of computer vision!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
