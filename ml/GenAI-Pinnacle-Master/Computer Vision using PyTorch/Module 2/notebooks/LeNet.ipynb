{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7885d369-b952-4b79-a530-f5e3ad2d450e",
   "metadata": {},
   "source": [
    "# Video: Building an Image Classification Model Using LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01eb1488-7491-4387-8581-fef1b0a98104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Cell 1: OS and version checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51cb28d95d60ee6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:26:23.581342Z",
     "start_time": "2025-03-30T02:26:23.578654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.0\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7967a333-169c-48ab-a4e2-5702b9ca0a87",
   "metadata": {},
   "source": [
    "#Cell 2: PyTorch core"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f0de862-8766-442d-a051-d43b20647d2d",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0057fddf-60bd-4aab-8e2c-e39be50e13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea018a14-a177-4a59-8d16-2ca96e66144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3265a60a-91ce-467e-b5a2-b705d2308bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5f2ddcd-4d69-47ca-871e-0f9f0111d5cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:25:33.553706Z",
     "start_time": "2025-03-30T02:25:33.503421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.0\n"
     ]
    }
   ],
   "source": [
    "#SPLIT THE LIBRARIES TO THEIR RESPECTIVE CELLS\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "print(torchvision.__version__)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514dc44d-ca01-4ded-8eb7-5dd77d0f981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarDataset(Dataset):\n",
    "    def __init__(self, root_dir, data, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_df = data\n",
    "        self.transform = transform\n",
    "        self.label_map = self._create_label_map()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data_df.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        label = self.data_df.iloc[idx, 1]\n",
    "        label = self.label_map[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _create_label_map(self):\n",
    "        unique_labels = sorted(self.data_df['label'].unique())\n",
    "        label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f330d537-3967-4f50-936d-785b65b433b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for data augmentation\n",
    "\n",
    "# Use this for colored images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Use this for BnW images\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((32, 32)),\n",
    "#     transforms.Grayscale(num_output_channels=1),  # Convert to black and white\n",
    "#     transforms.ToTensor(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a054570-34b1-4ce3-875a-84cb836aac31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:16:35.584153Z",
     "start_time": "2025-03-30T02:16:35.582051Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_root_dir = r'C:\\Users\\Deepak\\Downloads\\Computer Vision Resources\\Human Action Recognition\\New_train'\n",
    "# train_file = r'C:\\Users\\Deepak\\Downloads\\Computer Vision Resources\\Human Action Recognition\\Modified_Training_set.csv'\n",
    "# test_root_dir = r'C:\\Users\\Deepak\\Downloads\\Computer Vision Resources\\Human Action Recognition\\New_test'\n",
    "# test_file = r'C:\\Users\\Deepak\\Downloads\\Computer Vision Resources\\Human Action Recognition\\Reduced_Testing_set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fffa9526-35b2-4198-ad77-376ea45bc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_dir = '/Users/pvishnoi/PycharmProjects/data-etl-ml/ml/GenAI-Pinnacle-Master/Computer Vision using PyTorch/Module 2/Human Action Recognition/train'\n",
    "train_file = '/Users/pvishnoi/PycharmProjects/data-etl-ml/ml/GenAI-Pinnacle-Master/Computer Vision using PyTorch/Module 2/Human Action Recognition/Modified_Training_set.csv'\n",
    "test_root_dir = '/Users/pvishnoi/PycharmProjects/data-etl-ml/ml/GenAI-Pinnacle-Master/Computer Vision using PyTorch/Module 2/Human Action Recognition/test'\n",
    "test_file = '/Users/pvishnoi/PycharmProjects/data-etl-ml/ml/GenAI-Pinnacle-Master/Computer Vision using PyTorch/Module 2/Human Action Recognition/Reduced_Testing_set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dec4179-6c78-480d-9fc7-bdc8b8c22fa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:16:35.593912Z",
     "start_time": "2025-03-30T02:16:35.585195Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(train_file)\n",
    "# df_test = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f33c2918-db02-4887-8ec7-2b698002c32b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:16:35.603989Z",
     "start_time": "2025-03-30T02:16:35.595217Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train, df_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(df_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mdf_train\u001b[38;5;241m.\u001b[39mlabel)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a919fc-fc4b-413d-b82d-69be5baceabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71685c59-ed23-42c7-ae3b-06ddb996ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "train_dataset = HarDataset(root_dir=train_root_dir, data=df_train, transform=transform)\n",
    "val_dataset = HarDataset(root_dir=train_root_dir, data=df_val, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18a4f77-eb55-4584-a789-cddf79ea5f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:16:35.616529Z",
     "start_time": "2025-03-30T02:16:35.607059Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define data loaders\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "241eac44-9c02-4f8b-b5be-602e18ecfe90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:16:35.629053Z",
     "start_time": "2025-03-30T02:16:35.619916Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_label_map \u001b[38;5;241m=\u001b[39m {val: key \u001b[38;5;28;01mfor\u001b[39;00m (key, val) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mlabel_map\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "output_label_map = {val: key for (key, val) in train_dataset.label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafc390-895c-45c6-ba2e-c70d688eea23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:16:35.629946Z",
     "start_time": "2025-03-30T02:16:35.629897Z"
    }
   },
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4601273-f0c6-4dc8-8366-00b779c31e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique labels\n",
    "num_classes = len(train_dataset.label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc196ba-561c-4d7c-bd87-d8abf31995fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88145e-d70b-4b52-bf6f-220dcbac0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Checking class distribution\n",
    "class_distribution = df_train['label'].value_counts()\n",
    "\n",
    "# Print the class distribution\n",
    "print(class_distribution)\n",
    "\n",
    "# Plotting the class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_distribution.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution in the Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0408c3-4670-41bb-ac6b-ae3923e1d2e2",
   "metadata": {},
   "source": [
    "### LeNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eab4fda-a4e5-41a0-9e28-30d519286907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:16:35.652005Z",
     "start_time": "2025-03-30T02:16:35.633377Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define LeNet-5 model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLeNet5\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39mnum_classes):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(LeNet5, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m, in \u001b[0;36mLeNet5\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLeNet5\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[43mnum_classes\u001b[49m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(LeNet5, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# Define LeNet-5 model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.conv1(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef36132-4b92-4763-9464-9694148bc026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3bc00d-b28d-486c-abfd-a6ac8b9d7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035e6fc-6859-43a0-8925-3c5960dc6b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LeNet-5 model\n",
    "model = LeNet5().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f50416f4-6010-40d0-b009-e18342fcf077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:16:35.671485Z",
     "start_time": "2025-03-30T02:16:35.660041Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define loss function and optimizer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9351947-c69a-4a03-8a7b-dc7fc395de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 20\n",
    "best_accuracy = 0.0\n",
    "epochs_since_best = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100. * correct / total\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100. * correct / total\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Test Loss: {val_loss:.4f}, Test Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    # Check for best accuracy and stop if not improved after two more epochs\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        epochs_since_best = 0\n",
    "        print(f'New best accuracy: {best_accuracy:.2f}%')\n",
    "    else:\n",
    "        epochs_since_best += 1\n",
    "        if epochs_since_best > 2:\n",
    "            print(\"Stopping early: no improvement after two consecutive epochs.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a75866-9566-4348-b798-6d543a886f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_test.sample(10).iterrows():\n",
    "    img_path = os.path.join(test_root_dir, row['filename'])  \n",
    "    image_true = Image.open(img_path)  # Open the image file\n",
    "\n",
    "    # Transform the image and add a batch dimension\n",
    "    image = transform(image_true).unsqueeze(0).to(device)\n",
    "\n",
    "    # Pass the image through the model without computing gradients\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    # Get the predicted class label by finding the maximum in the output tensor\n",
    "    predicted_class = torch.argmax(output).item()\n",
    "\n",
    "    # Plot the image along with the predicted class label\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(image_true)\n",
    "    plt.title(f'Prediction: {output_label_map[predicted_class]}')  # Display the predicted label\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e515028-657a-4197-9135-8a03ddae5ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
